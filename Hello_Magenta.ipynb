{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TRIXMI/GreenSoftwareDirectory/blob/main/Hello_Magenta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WJfQVgaCwIpA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPkdg9jTjkTd"
      },
      "source": [
        "# Making music with Magenta\n",
        "\n",
        "[Magenta](https://magenta.tensorflow.org/) is a Python library that helps you generate art and music. In this tutorial, we'll talk about the music generation bits in `note_seq` -- how to make your browser sing, and in particular, how to make your browser sing like you!\n",
        "\n",
        "As a library, `note_seq` can help you:\n",
        "- make music using some of the neat abstractions and utilities in the library\n",
        "- use Machine Learning models to generate music."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R122bwRNbTus"
      },
      "source": [
        "# Basic Instructions\n",
        "\n",
        "1. Double click on the hidden cells to make them visible, or select \"View > Expand Sections\" in the menu at the top.\n",
        "2. Hover over the \"`[ ]`\" in the top-left corner of each cell and click on the \"Play\" button to run it, in order.\n",
        "3. Listen to the generated samples.\n",
        "4. Make it your own: copy the notebook, modify the code, train your own models, upload your own MIDI, etc. See the Magenta code on [GitHub](https://github.com/magenta/magenta) for more information!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJbq5TmtFJUU"
      },
      "source": [
        "# Step 0: First things first!\n",
        "If you're going to use `Magenta`, you need to install it and its dependencies. Some of the later examples will also download other dependencies (such as models and checkpoints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 960
        },
        "id": "PfRDVhNs3UFx",
        "outputId": "bd8fdecb-8446-4a17-ed51-579938813287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "E: Package 'libfluidsynth2' has no installation candidate\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.5/204.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Importing libraries and defining some helper functions...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'magenta'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2864784903>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmagenta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnote_seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'magenta'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "print('Installing dependencies...')\n",
        "!apt-get update -qq && apt-get install -qq libfluidsynth2 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
        "!pip install -qU pyfluidsynth pretty_midi\n",
        "\n",
        "!pip install -qU magenta\n",
        "\n",
        "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
        "# This is only needed for the hosted Colab environment.\n",
        "import ctypes.util\n",
        "orig_ctypes_util_find_library = ctypes.util.find_library\n",
        "def proxy_find_library(lib):\n",
        "  if lib == 'fluidsynth':\n",
        "    return 'libfluidsynth.so.1'\n",
        "  else:\n",
        "    return orig_ctypes_util_find_library(lib)\n",
        "ctypes.util.find_library = proxy_find_library\n",
        "\n",
        "print('Importing libraries and defining some helper functions...')\n",
        "from google.colab import files\n",
        "\n",
        "import magenta\n",
        "import note_seq\n",
        "import tensorflow\n",
        "\n",
        "print('🎉 Done!')\n",
        "print(magenta.__version__)\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLSgiA6Uktpm"
      },
      "source": [
        "# Step 1. Making sounds with NoteSequences\n",
        "\n",
        "Everything in `Magenta` is centered around [NoteSequences](https://github.com/magenta/note-seq/blob/main/note_seq/protobuf/music.proto#L27). This is an abstract representation of a series of notes, each with different pitches, instruments and strike velocities, much like [MIDI](https://en.wikipedia.org/wiki/MIDI).\n",
        "\n",
        "For example, this is a `NoteSequence` that represents \"Twinkle Twinkle Little Star\". Try changing the pitches to see how the sound changes!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71dgCmmBli-s"
      },
      "outputs": [],
      "source": [
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "twinkle_twinkle = music_pb2.NoteSequence()\n",
        "\n",
        "# Add the notes to the sequence.\n",
        "twinkle_twinkle.notes.add(pitch=60, start_time=0.0, end_time=0.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=60, start_time=0.5, end_time=1.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=67, start_time=1.0, end_time=1.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=67, start_time=1.5, end_time=2.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=69, start_time=2.0, end_time=2.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=69, start_time=2.5, end_time=3.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=67, start_time=3.0, end_time=4.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=65, start_time=4.0, end_time=4.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=65, start_time=4.5, end_time=5.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=64, start_time=5.0, end_time=5.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=64, start_time=5.5, end_time=6.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=62, start_time=6.0, end_time=6.5, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=62, start_time=6.5, end_time=7.0, velocity=80)\n",
        "twinkle_twinkle.notes.add(pitch=60, start_time=7.0, end_time=8.0, velocity=80)\n",
        "twinkle_twinkle.total_time = 8\n",
        "\n",
        "twinkle_twinkle.tempos.add(qpm=60);\n",
        "\n",
        "# This is a colab utility method that visualizes a NoteSequence.\n",
        "note_seq.plot_sequence(twinkle_twinkle)\n",
        "\n",
        "# This is a colab utility method that plays a NoteSequence.\n",
        "note_seq.play_sequence(twinkle_twinkle,synth=note_seq.fluidsynth)\n",
        "\n",
        "# Here's another NoteSequence!\n",
        "teapot = music_pb2.NoteSequence()\n",
        "teapot.notes.add(pitch=69, start_time=0, end_time=0.5, velocity=80)\n",
        "teapot.notes.add(pitch=71, start_time=0.5, end_time=1, velocity=80)\n",
        "teapot.notes.add(pitch=73, start_time=1, end_time=1.5, velocity=80)\n",
        "teapot.notes.add(pitch=74, start_time=1.5, end_time=2, velocity=80)\n",
        "teapot.notes.add(pitch=76, start_time=2, end_time=2.5, velocity=80)\n",
        "teapot.notes.add(pitch=81, start_time=3, end_time=4, velocity=80)\n",
        "teapot.notes.add(pitch=78, start_time=4, end_time=5, velocity=80)\n",
        "teapot.notes.add(pitch=81, start_time=5, end_time=6, velocity=80)\n",
        "teapot.notes.add(pitch=76, start_time=6, end_time=8, velocity=80)\n",
        "teapot.total_time = 8\n",
        "\n",
        "teapot.tempos.add(qpm=60);\n",
        "\n",
        "note_seq.plot_sequence(teapot)\n",
        "note_seq.play_sequence(teapot,synth=note_seq.synthesize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oC7BS_4OwCIR"
      },
      "source": [
        "You can use other instruments for your sequences. For example, the sequence below should sound like a drum solo!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQLjca9SwOiI"
      },
      "outputs": [],
      "source": [
        "drums = music_pb2.NoteSequence()\n",
        "\n",
        "drums.notes.add(pitch=36, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=38, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=46, start_time=0, end_time=0.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.25, end_time=0.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.375, end_time=0.5, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.5, end_time=0.625, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=50, start_time=0.5, end_time=0.625, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=36, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=38, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=45, start_time=0.75, end_time=0.875, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=36, start_time=1, end_time=1.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=1, end_time=1.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=46, start_time=1, end_time=1.125, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=42, start_time=1.25, end_time=1.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=48, start_time=1.25, end_time=1.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.notes.add(pitch=50, start_time=1.25, end_time=1.375, is_drum=True, instrument=10, velocity=80)\n",
        "drums.total_time = 1.375\n",
        "\n",
        "drums.tempos.add(qpm=60)\n",
        "\n",
        "# This is a colab utility method that visualizes a NoteSequence.\n",
        "note_seq.plot_sequence(drums)\n",
        "\n",
        "# This is a colab utility method that plays a NoteSequence.\n",
        "note_seq.play_sequence(drums,synth=note_seq.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhtRBNNf05CA"
      },
      "source": [
        "## Converting a `NoteSequence` to MIDI\n",
        "\n",
        "When you called the \"play_sequence\" method above, this converted the `NoteSequence` to MIDI, and created an HTML widget to play it. This method is specially made for colab notebooks, so it won't work inside your Python script. That method uses the Magenta built-in [conversion methods](https://github.com/magenta/note-seq/blob/main/note_seq/midi_io.py#L51), which you can use in your python script:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcmmAToP4WE3"
      },
      "outputs": [],
      "source": [
        "# This creates a file called `drums_sample_output.mid`, containing the drums solo we've been using.\n",
        "note_seq.sequence_proto_to_midi_file(drums, 'drums_sample_output.mid')\n",
        "\n",
        "# This is a colab utility method to download that file. In your Python script, you\n",
        "# would just write it to disk.\n",
        "files.download('drums_sample_output.mid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YalOCM_5JP6"
      },
      "source": [
        "## Useful helpers\n",
        "There are a lot of other helper methods sprinkled around the `note_seq` codebase that you might need but not know where to find. Here are some of our favourites:\n",
        "\n",
        "- [converting](https://github.com/magenta/note-seq/blob/main/note_seq/midi_io.py) between MIDI and NoteSequences\n",
        "- [trimming, concatenating and expanding](https://github.com/magenta/note-seq/blob/main/note_seq/sequences_lib.py) NoteSequences\n",
        "- [colab notebook](https://github.com/magenta/note-seq/blob/main/note_seq/notebook_utils.py) utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1o5dZjR57c_"
      },
      "source": [
        "# Step 2. Using Machine Learning to make music\n",
        "\n",
        "`note_seq` has several Machine Learning models, each with different strengths. All models are built with [Tensorflow](https://www.tensorflow.org), so they will run faster if you can run them on a GPU. Here are some of the most popular ones:\n",
        "\n",
        "- [**MelodyRNN**](https://github.com/magenta/magenta/tree/main/magenta/models/melody_rnn) - you give it a NoteSequence, and it continues it in the style of your original NoteSequence.\n",
        "- [**MusicVAE**](https://github.com/magenta/magenta/tree/main/magenta/models/music_vae) - generates brand new NoteSequences or interpolates between two sequences.\n",
        "- [**Onsets and Frames**](https://github.com/magenta/magenta/tree/main/magenta/models/onsets_frames_transcription) -- transcribes piano audio\n",
        "\n",
        "Now that we know how to use `NoteSequences`, adding some basic Machine Learning is a continuation of that. The pattern for using any of these models is:\n",
        "\n",
        "- Load `note_seq` (which we already know how to do!)\n",
        "- Create a model from a downloaded checkpoint (i.e. where the weights, or the encoding, of the model lives)\n",
        "- Ask the model to do something."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pm3kdH0-DaH"
      },
      "source": [
        "## Melody RNN\n",
        "\n",
        "A MelodyRNN is an [LSTM-based](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) language model for musical notes -- it is best at continuing a NoteSequence that you give it.\n",
        "\n",
        "To use it, you need to give it a sequence to continue and the model will return the following sequence.\n",
        "\n",
        "This example shows how to use the basic Melody RNN model -- check out the [docs](https://github.com/magenta/magenta/tree/main/magenta/models/melody_rnn) for the other models, such as `lookback_rnn` and `attention_rnn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdPBBzSY-P38"
      },
      "source": [
        "### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y0VkNafNKLP"
      },
      "outputs": [],
      "source": [
        "print('Downloading model bundle. This will take less than a minute...')\n",
        "note_seq.notebook_utils.download_bundle('basic_rnn.mag', '/content/')\n",
        "\n",
        "# Import dependencies.\n",
        "from magenta.models.melody_rnn import melody_rnn_sequence_generator\n",
        "from magenta.models.shared import sequence_generator_bundle\n",
        "from note_seq.protobuf import generator_pb2\n",
        "from note_seq.protobuf import music_pb2\n",
        "\n",
        "# Initialize the model.\n",
        "print(\"Initializing Melody RNN...\")\n",
        "bundle = sequence_generator_bundle.read_bundle_file('/content/basic_rnn.mag')\n",
        "generator_map = melody_rnn_sequence_generator.get_generator_map()\n",
        "melody_rnn = generator_map['basic_rnn'](checkpoint=None, bundle=bundle)\n",
        "melody_rnn.initialize()\n",
        "\n",
        "print('🎉 Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlYDyTA0-UJT"
      },
      "source": [
        "### Continuing a sequence\n",
        "\n",
        "With Melody RNN, you can configure the number of steps the new sequence will be, as well as the \"temperature\" of the result -- the higher the temperature, the more random (and less like the input) your sequence will be. You can play around with these values and see how the resulting sequences are different:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgREckzBmd-8"
      },
      "outputs": [],
      "source": [
        "# Model options. Change these to get different generated sequences!\n",
        "\n",
        "input_sequence = twinkle_twinkle # change this to teapot if you want\n",
        "num_steps = 128 # change this for shorter or longer sequences\n",
        "temperature = 1.0 # the higher the temperature the more random the sequence.\n",
        "\n",
        "# Set the start time to begin on the next step after the last note ends.\n",
        "last_end_time = (max(n.end_time for n in input_sequence.notes)\n",
        "                  if input_sequence.notes else 0)\n",
        "qpm = input_sequence.tempos[0].qpm\n",
        "seconds_per_step = 60.0 / qpm / melody_rnn.steps_per_quarter\n",
        "total_seconds = num_steps * seconds_per_step\n",
        "\n",
        "generator_options = generator_pb2.GeneratorOptions()\n",
        "generator_options.args['temperature'].float_value = temperature\n",
        "generate_section = generator_options.generate_sections.add(\n",
        "  start_time=last_end_time + seconds_per_step,\n",
        "  end_time=total_seconds)\n",
        "\n",
        "# Ask the model to continue the sequence.\n",
        "sequence = melody_rnn.generate(input_sequence, generator_options)\n",
        "\n",
        "note_seq.plot_sequence(sequence)\n",
        "note_seq.play_sequence(sequence, synth=note_seq.fluidsynth)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zp--0n5FSDm"
      },
      "source": [
        "## Music VAE\n",
        "\n",
        "A [MusicVAE](https://g.co/magenta/musicvae) is a variational autoencoder made up of an Encoder and Decoder -- you can think of the encoder as trying to summarize all the data you give it, and the decoder as trying to recreate the original data, based on this summarized version. As a generative model, you can think of a VAE as coming up with new sequences that could be a decoding of some summarized version.\n",
        "\n",
        "The Music VAE implementation in `magenta/music` in particular does two things: it can create new sequences (which are reconstructions or variations of the input data), or it can interpolate between two."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcx5W1417IP3"
      },
      "source": [
        "### Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "FDW3h0cqUERq"
      },
      "outputs": [],
      "source": [
        "print('Copying checkpoint from GCS. This will take less than a minute...')\n",
        "# This will download the mel_2bar_big checkpoint. There are more checkpoints that you\n",
        "# can use with this model, depending on what kind of output you want\n",
        "# See the list of checkpoints: https://github.com/magenta/magenta/tree/main/magenta/models/music_vae#pre-trained-checkpoints\n",
        "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab2/checkpoints/mel_2bar_big.ckpt.* /content/\n",
        "\n",
        "# Import dependencies.\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel\n",
        "\n",
        "# Initialize the model.\n",
        "print(\"Initializing Music VAE...\")\n",
        "music_vae = TrainedModel(\n",
        "      configs.CONFIG_MAP['cat-mel_2bar_big'],\n",
        "      batch_size=4,\n",
        "      checkpoint_dir_or_path='/content/mel_2bar_big.ckpt')\n",
        "\n",
        "print('🎉 Done!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APjD-ph4Fn3Q"
      },
      "source": [
        "### Creating new sequences\n",
        "\n",
        "With Music VAE, you can configure how many new sequences to generate, the number of steps the new sequence will be, as well as the \"temperature\" of the result -- the higher the temperature, the more random (and less like the input) your sequence will be. You can play around with these values and see how the resulting sequences are different:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "both",
        "id": "XKk8rGihUR6B"
      },
      "outputs": [],
      "source": [
        "generated_sequences = music_vae.sample(n=2, length=80, temperature=1.0)\n",
        "\n",
        "for ns in generated_sequences:\n",
        "  # print(ns)\n",
        "  note_seq.plot_sequence(ns)\n",
        "  note_seq.play_sequence(ns, synth=note_seq.fluidsynth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSq4nJfL-Y2y"
      },
      "source": [
        "### Interpolating between two sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjHUvtn5-daA"
      },
      "outputs": [],
      "source": [
        "# We're going to interpolate between the Twinkle Twinkle Little Star\n",
        "# NoteSequence we defined in the first section, and one of the generated\n",
        "# sequences from the previous VAE example\n",
        "\n",
        "# How many sequences, including the start and end ones, to generate.\n",
        "num_steps = 8;\n",
        "\n",
        "# This gives us a list of sequences.\n",
        "note_sequences = music_vae.interpolate(\n",
        "      twinkle_twinkle,\n",
        "      teapot,\n",
        "      num_steps=num_steps,\n",
        "      length=32)\n",
        "\n",
        "# Concatenate them into one long sequence, with the start and\n",
        "# end sequences at each end.\n",
        "interp_seq = note_seq.sequences_lib.concatenate_sequences(note_sequences)\n",
        "\n",
        "note_seq.play_sequence(interp_seq, synth=note_seq.fluidsynth)\n",
        "note_seq.plot_sequence(interp_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho6gRbJ4Qgkj"
      },
      "source": [
        "# That's it!\n",
        "\n",
        "You're now ready to build your own amazing, Machine Learning powered, music instrument! If you want more information, you can check out:\n",
        "\n",
        "- some [demos](https://magenta.tensorflow.org/demos) `#MadeWithMagenta`\n",
        "- some more of our [Colab notebooks](https://magenta.tensorflow.org/demos#colab-notebooks)\n",
        "- the [documentation](https://github.com/magenta/magenta)\n",
        "- the [Magenta blog](https://magenta.tensorflow.org/blog), which talks about all the mathy bits we skipped.\n",
        "\n",
        "Have fun! 💕"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Hello Magenta.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}